{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0df68f9c-62e7-4bd4-9c38-52beb96e9fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded successfully.\n",
      "Preprocessing data...\n",
      "Encoding categorical features...\n",
      "Categorical features encoded successfully.\n",
      "Scaling numerical features...\n",
      "Numerical features scaled successfully.\n",
      "Combining processed features...\n",
      "Features combined successfully.\n",
      "Splitting data into training and test sets...\n",
      "Data split successfully.\n",
      "Training the model...\n",
      "Model trained successfully in 128.66 seconds\n",
      "Evaluating the model...\n",
      "AUC Score on the test set: 0.8738\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99    157853\n",
      "         1.0       0.40      0.01      0.02      2147\n",
      "\n",
      "    accuracy                           0.99    160000\n",
      "   macro avg       0.70      0.50      0.50    160000\n",
      "weighted avg       0.98      0.99      0.98    160000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Step 1: Load data\n",
    "print(\"Loading data...\")\n",
    "data_path = 'train.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# Step 2: Data preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "target = 'target'\n",
    "features = [col for col in df.columns if col not in ['id', target]]\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "categorical_features = [col for col in X.columns if col.startswith('cat_')]\n",
    "numerical_features = [col for col in X.columns if col.startswith('num_')]\n",
    "\n",
    "# Encode categorical features\n",
    "print(\"Encoding categorical features...\")\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_categorical_encoded = encoder.fit_transform(X[categorical_features])\n",
    "print(\"Categorical features encoded successfully.\")\n",
    "\n",
    "# Scale numerical features (if any)\n",
    "if numerical_features:\n",
    "    print(\"Scaling numerical features...\")\n",
    "    scaler = StandardScaler()\n",
    "    X_numerical_scaled = scaler.fit_transform(X[numerical_features])\n",
    "    # Convert numerical features to sparse matrix to save memory\n",
    "    X_numerical_sparse = csr_matrix(X_numerical_scaled.astype(np.float32))\n",
    "    print(\"Numerical features scaled successfully.\")\n",
    "else:\n",
    "    X_numerical_sparse = None\n",
    "\n",
    "# Combine processed features\n",
    "print(\"Combining processed features...\")\n",
    "if X_numerical_sparse is not None:\n",
    "    X_processed = hstack([X_categorical_encoded, X_numerical_sparse]).tocsr()\n",
    "else:\n",
    "    X_processed = X_categorical_encoded\n",
    "print(\"Features combined successfully.\")\n",
    "\n",
    "# Step 3: Split data into training and test sets\n",
    "print(\"Splitting data into training and test sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split successfully.\")\n",
    "\n",
    "# Step 4: Build and train the logistic regression model\n",
    "print(\"Training the model...\")\n",
    "start_time = time.time()\n",
    "model = LogisticRegression(max_iter=5000, solver='lbfgs')\n",
    "model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Model trained successfully in {training_time:.2f} seconds\")\n",
    "\n",
    "# Step 5: Predict and evaluate\n",
    "print(\"Evaluating the model...\")\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AUC Score on the test set: {auc_score:.4f}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e40e66-7d10-49a8-8c22-c89e927322f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
