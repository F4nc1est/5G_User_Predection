{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09bea7be-7d45-4853-973a-e5a659c1da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Required libraries imported.\n",
      "2. Loading data...\n",
      "Data loaded.\n",
      "3. Extracting features and target variables...\n",
      "Features and target variables extracted.\n",
      "4. Defining numeric and categorical feature names...\n",
      "Feature names defined.\n",
      "5. Splitting the data into training and testing sets...\n",
      "Data split into training and testing sets.\n",
      "6. Defining preprocessing steps...\n",
      "Preprocessing steps defined.\n",
      "7. Defining the AdaBoosting model pipeline...\n",
      "Model pipeline defined.\n",
      "8. Training the model...\n",
      "Model training completed.\n",
      "9. Making predictions...\n",
      "Predictions made.\n",
      "10. Evaluating the model...\n",
      "AdaBoosting AUC: 0.8814\n",
      "Training Time (seconds): 197.2767\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"1. Required libraries imported.\")\n",
    "\n",
    "# Load data\n",
    "print(\"2. Loading data...\")\n",
    "data = pd.read_csv('train.csv')\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# Extract features and target variables\n",
    "print(\"3. Extracting features and target variables...\")\n",
    "X = data.drop(['id', 'target'], axis=1)\n",
    "y = data['target']\n",
    "print(\"Features and target variables extracted.\")\n",
    "\n",
    "# Define numeric and categorical feature names\n",
    "print(\"4. Defining numeric and categorical feature names...\")\n",
    "numeric_features = [f'num_{i}' for i in range(38)]\n",
    "categorical_features = [f'cat_{i}' for i in range(20)]\n",
    "print(\"Feature names defined.\")\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "print(\"5. Splitting the data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split into training and testing sets.\")\n",
    "\n",
    "# Define preprocessing steps\n",
    "print(\"6. Defining preprocessing steps...\")\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "print(\"Preprocessing steps defined.\")\n",
    "\n",
    "# Define the AdaBoosting model pipeline\n",
    "print(\"7. Defining the AdaBoosting model pipeline...\")\n",
    "adaboost_model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('classifier', AdaBoostClassifier(n_estimators=50, algorithm='SAMME', random_state=42))])\n",
    "print(\"Model pipeline defined.\")\n",
    "\n",
    "# Record training time and train the model\n",
    "print(\"8. Training the model...\")\n",
    "start_time = time.time()\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Model training completed.\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"9. Making predictions...\")\n",
    "y_pred_proba = adaboost_model.predict_proba(X_test)[:, 1]\n",
    "print(\"Predictions made.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"10. Evaluating the model...\")\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"AdaBoosting AUC: {auc_score:.4f}\")\n",
    "print(f\"Training Time (seconds): {training_time:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544bf5c9-cdd3-42dd-a16d-0d5320faffd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
